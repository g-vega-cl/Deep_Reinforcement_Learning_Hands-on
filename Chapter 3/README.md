Chapter 3 and some notes:

<p>DL practitioners have developed a list of things that you should observe during your training, which usually includes the following:</p>

<ul>
	<li>Loss value, which normally consists of several components like base loss and regularization losses. You should monitor both total loss and individual components over time.</li>
	<li>Results of validation on training and test sets.</li>
	<li>Statistics about gradients and weights.</li>
	<li>Learning rates and other hyperparameters, if they are adjusted over time.</li>
</ul>

<p>The list could be much longer and include domain-specific metrics, such as word embeddings' projections, audio samples, and images generated by GAN. You also may want to monitor values related to training speed, like how long an epoch takes, to see the effect of your optimizations or problems with hardware.</p>

<h3>Use tensorboard</h3>
<p>In fact, at the time of writing, there are not many alternatives to choose from, especially open source and generic ones. From the first public version, TensorFlow included a special tool called TensorBoard, developed to solve the problem we are talking about: how to observe and analyze various NN characteristics over training. TensorBoard is a powerful, generic solution with a large community and it looks quite pretty:</p>

<h4>TO RUN TENSORBOARD:</h4>
<p>python -m tensorboard.main --logdir="./runs"</p>